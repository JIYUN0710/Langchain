import streamlit as st
from langchain_openai import ChatOpenAI
import os
import bs4
from langchain import hub
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.document_loaders import WebBaseLoader
from langchain_community.vectorstores import FAISS
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.document_loaders.csv_loader import CSVLoader
from langchain_upstage import ChatUpstage
from langchain_upstage import UpstageEmbeddings
from langchain_core.prompts import PromptTemplate

# Streamlit UI ì„¤ì •
st.set_page_config(page_title="ì œ2ì˜ ë‚˜ë¼ chatbot", page_icon=":video_game:")
st.title("ğŸ’Ÿ netmarble ğŸ’Ÿ")
st.header("âœ¨ ì œ2ì˜ ë‚˜ë¼: Cross Worlds âœ¨")
st.caption("ğŸ˜„ Jiyun Park ğŸ˜„")

with st.sidebar:
    upstage_api_key = st.text_input("Upstage API Key", key="chatbot_api_key", type="password")
if upstage_api_key:
    os.environ["UPSTAGE_API_KEY"] = upstage_api_key
else:
    st.info("Upstage API Keyë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    st.stop()

# CSV íŒŒì¼ ê²½ë¡œ ì…ë ¥
import streamlit as st
import pandas as pd


#csv_file_path = "C:/Users/jyp/.conda/envs/langchain-cource/00_PT/total_with_images_fake.csv"
csv_file_path = "total_with_images.csv"
loader = CSVLoader(file_path=csv_file_path)
docs = loader.load()



# text splitter
text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
splits = text_splitter.split_documents(docs)

# vectorstore & retriever
vectorstore = FAISS.from_documents(splits, UpstageEmbeddings(model="solar-embedding-1-large"))
retriever = vectorstore.as_retriever()

# prompt
from langchain_core.prompts import PromptTemplate

prompt = PromptTemplate.from_template(
    """
    ë‹¹ì‹ ì€ ì§ˆë¬¸-ë‹µë³€(Question-Answering)ì„ ìˆ˜í–‰í•˜ëŠ” ì¹œì ˆí•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. 
    ë‹¹ì‹ ì˜ ì„ë¬´ëŠ” ì£¼ì–´ì§„ ë¬¸ë§¥(context) ì—ì„œ ì£¼ì–´ì§„ ì§ˆë¬¸(question) ì— ë‹µí•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.
    ê²€ìƒ‰ëœ ë‹¤ìŒ ë¬¸ë§¥(context) ì„ ì‚¬ìš©í•˜ì—¬ ì§ˆë¬¸(question) ì— ë‹µí•˜ì„¸ìš”. 
    ë§Œì•½, ì£¼ì–´ì§„ ë¬¸ë§¥(context) ì—ì„œ ë‹µì„ ì°¾ì„ ìˆ˜ ì—†ë‹¤ë©´, 
    ë‹µì„ ëª¨ë¥¸ë‹¤ë©´ `ì£¼ì–´ì§„ ì •ë³´ì—ì„œ ì§ˆë¬¸ì— ëŒ€í•œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤` ë¼ê³  ë‹µí•˜ì„¸ìš”.
    í•œê¸€ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”. ë‹¨, ê¸°ìˆ ì ì¸ ìš©ì–´ë‚˜ ì´ë¦„ì€ ë²ˆì—­í•˜ì§€ ì•Šê³  ê·¸ëŒ€ë¡œ ì‚¬ìš©í•´ ì£¼ì„¸ìš”.
    ê·¸ë¦¬ê³  ë‹¹ì‹ ì„ ì‚¬ìš©í•˜ëŠ” ì‚¬ëŒë“¤ì„ ë„·ë§ˆë¸”ì˜ "ì œ2ì˜ ë‚˜ë¼"ë¼ëŠ” ëª¨ë°”ì¼ ê²Œì„ì˜ ìœ ì €ì™€ ìš´ì˜ìì…ë‹ˆë‹¤. 
    Don't narrate the answer, just answer the question. Let's think step-by-step.

    #Question: 
    {question} 

    #Context: 
    {context} 

    #Answer:
    """
)


# prompt = hub.pull("teddynote/rag-prompt-korean")
# prompt

llm = ChatUpstage()
rag_chain = (
    {"context": retriever, "question": RunnablePassthrough()}
    | prompt
    | llm
    | StrOutputParser()
)

class StreamChain:
    def __init__(self, chain):
        self.chain = chain

    def stream(self, query):
        response = self.chain.stream(query)
        complete_response = ""
        for token in response:
            print(token, end="", flush=True)
            complete_response += token
        return complete_response


# ìƒì„±ìì— chain ì„ ë§¤ê°œë³€ìˆ˜ë¡œ ì „ë‹¬í•˜ì—¬ chain ê°ì²´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
chain = StreamChain(rag_chain)


# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "system", "content": "You are a helpful assistant."}
    ]

# ëŒ€í™” íˆìŠ¤í† ë¦¬ í‘œì‹œ
for message in st.session_state.messages:
    if message["role"] != "system":
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
prompt = st.chat_input("ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?")

if prompt:
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)
    
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        full_response = ""
        for response in chain.stream(prompt):
            full_response += response
            message_placeholder.markdown(full_response + "â–Œ")
        message_placeholder.markdown(full_response)
    st.session_state.messages.append({"role": "assistant", "content": full_response})

# ìŠ¤í¬ë¡¤ì„ ìµœí•˜ë‹¨ìœ¼ë¡œ ì´ë™
st.empty()
